% Encoding: UTF-8

@InProceedings{He2019,
  author          = {Tong He and Zhi Zhang and Hang Zhang and Zhongyue Zhang and Junyuan Xie and Mu Li},
  title           = {Bag of Tricks for Image Classification with Convolutional Neural Networks},
  year            = {2019},
  pages           = {558--567},
  publisher       = {IEEE},
  abstract        = {Much of the recent progress made in image classification research can be credited to training procedure refinements, such as changes in data augmentations and optimization methods. In the literature, however, most refinements are either briefly mentioned as implementation details or only visible in source code. In this paper, we will examine a collection of such refinements and empirically evaluate their impact on the final model accuracy through ablation study. We will show that, by combining these refinements together, we are able to improve various CNN models significantly. For example, we raise ResNet-50's top-1 validation accuracy from 75.3% to 79.29% on ImageNet. We will also demonstrate that improvement on image classification accuracy leads to better transfer learning performance in other application domains such as object detection and semantic segmentation.},
  date            = {15-20 June 2019},
  doi             = {10.1109/CVPR.2019.00065},
  eventdate       = {15-20 June 2019},
  eventtitleaddon = {Long Beach, CA, USA},
  file            = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8954382:PDF},
  isbn            = {978-1-7281-3294-5},
  issn            = {1063-6919},
  journaltitle    = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  keywords        = {Deep Learning, Recognition: Detection, Categorization, Retrieval},
  location        = {Long Beach, CA, USA},
}

@Article{Liu2018,
  author       = {Na Liu and Lihong Wan and Yu Zhang and Tao Zhou and Hong Huo and Tao Fang},
  title        = {Exploiting Convolutional Neural Networks With Deeply Local Description for Remote Sensing Image Classification},
  year         = {2018},
  issn         = {2169-3536},
  pages        = {11215--11228},
  volume       = {6},
  abstract     = {The extraction of features from the fully connected layer of a convolutional neural network (CNN) model is widely used for image representation. However, the features obtained by the convolutional layers are seldom investigated due to their high dimensionality and lack of global representation. In this study, we explore the uses of local description and feature encoding for deeply convolutional features. Given an input image, the image pyramid is constructed, and different pretrained CNNs are applied to each image scale to extract convolutional features. Deeply local descriptors can be obtained by concatenating the convolutional features in each spatial position. Hellinger kernel and principal component analysis (PCA) are introduced to improve the distinguishable capabilities of the deeply local descriptors. The Hellinger kernel causes the distance measure to be sensitive to small feature values, and the PCA helps reduce feature redundancy. In addition, two aggregate strategies are proposed to form global image representations from the deeply local descriptors. The first strategy aggregates the descriptors of different CNNs by Fisher encoding, and the second strategy concatenates the Fisher vectors of different CNNs. Experiments on two remote sensing image datasets illustrate that the Hellinger kernel, PCA, and two aggregate strategies improve classification performance. Moreover, the deeply local descriptors outperform the features extracted from fully connected layers.},
  date         = {2018},
  doi          = {10.1109/ACCESS.2018.2798799},
  file         = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8270691:PDF},
  journaltitle = {IEEE Access},
  keywords     = {Feature extraction, Encoding, Kernel, Aggregates, Principal component analysis, Remote sensing, Convolutional neural networks, Convolutional neural networks (CNN), image classification, local description, remote sensing},
  publisher    = {IEEE},
}

@InProceedings{Lai2019,
  author          = {Can Lai and Tao Liu and RuoWei Mei and HaiJiang Wang and ShiPeng Hu},
  title           = {The Cloud Images Classification Based on Convolutional Neural Network},
  year            = {2019},
  pages           = {1--4},
  publisher       = {IEEE},
  abstract        = {In order to achieve the goal of clouds images classification, a deep-learning method based on Convolutional Neural Network (CNN) is adopted.2300 raw true-color images of eight types of clouds are collected as the datasets from the website www.baidu.com, along with the corresponding labels. Before feeding to machine learning, some preprocessing steps are conducted. Firstly, every photo is preprocessed using the method of the sliding window that can crop the initial photo into a series of sub-images with 200*200 pixels and RGB channels. Not only can this step increase the size of datasets, but it also can make more features reserved from inputs. Next, the image histogram equalization is adopted. Besides, In the CNN network construction, the ReLU activation function is placed directly after the convolutional layer when there isn't a BN layer behind it, while the ReLU function is placed after the BN layer if the BN layer exists. This kind of structure is designed to avoid the overfitting problem. The result obviously performs better when adopts more large and comprehensive datasets than that when datasets are unhandled. Meanwhile, owing to the MBSD gradient algorithm, the adjustment of arguments and layers can influence the final results as well. The classification accuracy has reached a comparatively high value, which can nearly meet our requirements.},
  date            = {28-31 Dec. 2019},
  doi             = {10.1109/ICMO49322.2019.9026121},
  eventdate       = {28-31 Dec. 2019},
  eventtitleaddon = {Chengdu, China},
  file            = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9026121:PDF},
  isbn            = {978-1-7281-6255-3},
  journaltitle    = {2019 International Conference on Meteorology Observations (ICMO)},
  keywords        = {Training, Clouds, Convolutional neural networks, Image classification, Information technology, Cost function, cloud images classification, Convolutional Neural Network, preprocessing steps, over-fitting problem},
  location        = {Chengdu, China},
}

@InProceedings{Seo2018,
  author          = {Yian Seo and Kyung-shik Shin},
  title           = {Image classification of fine-grained fashion image based on style using pre-trained convolutional neural network},
  year            = {2018},
  pages           = {387--390},
  publisher       = {IEEE},
  abstract        = {Deep learning has emerged as a new methodology with continuous interests in artificial intelligence, and it can be applied in various business fields for better performance. In fashion business, deep learning, especially Convolutional Neural Network (CNN), is used in classification of apparel image. However, apparel classification can be difficult due to various apparel categories and lack of labeled image data for each category. Therefore, we propose to pre-train the GoogLeNet architecture on ImageNet dataset and fine-tune on our fine-grained fashion dataset based on design attributes. This will complement the small size of dataset and reduce the training time. After 10-fold experiments, the average final test accuracy results 62%.},
  date            = {9-12 March 2018},
  doi             = {10.1109/ICBDA.2018.8367713},
  eventdate       = {9-12 March 2018},
  eventtitleaddon = {Shanghai},
  file            = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8367713:PDF},
  isbn            = {978-1-5386-4795-0},
  journaltitle    = {2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA)},
  keywords        = {Training, Convolutional neural networks, Computer architecture, IEEE Press, Image classification, Machine learning, Feature extraction, Convolutional Neural Network, fashion image, fine-grained classification, pre-trained network},
  location        = {Shanghai},
}

@Article{Shomron2019,
  author       = {Gil Shomron and Uri Weiser},
  title        = {Spatial Correlation and Value Prediction in Convolutional Neural Networks},
  year         = {2019},
  issn         = {2473-2575},
  pages        = {10--13},
  volume       = {18},
  abstract     = {Convolutional neural networks (CNNs) are a widely used form of deep neural networks, introducing state-of-the-art results for different problems such as image classification, computer vision tasks, and speech recognition. However, CNNs are compute intensive, requiring billions of multiply-accumulate (MAC) operations per input. To reduce the number of MACs in CNNs, we propose a value prediction method that exploits the spatial correlation of zero-valued activations within the CNN output feature maps, thereby saving convolution operations. Our method reduces the number of MAC operations by 30.4 percent, averaged on three modern CNNs for ImageNet, with top-1 accuracy degradation of 1.7 percent, and top-5 accuracy degradation of 1.1 percent.},
  date         = {1 Jan.-June 2019},
  doi          = {10.1109/LCA.2018.2890236},
  file         = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8594568:PDF},
  issue        = {1},
  journaltitle = {IEEE Computer Architecture Letters},
  keywords     = {Microsoft Windows, Correlation, Convolution, Degradation, Predictive models, Neural networks, Deep neural networks, convolutional neural network, value prediction},
  publisher    = {IEEE},
}

@Article{Xia2019,
  author       = {Shuyin Xia and Yulong Xia and Hong Yu and Qun Liu and Yueguo Luo and Guoyin Wang and Zizhong Chen},
  title        = {Transferring Ensemble Representations Using Deep Convolutional Neural Networks for Small-Scale Image Classification},
  year         = {2019},
  issn         = {2169-3536},
  pages        = {168175--168186},
  volume       = {7},
  abstract     = {The deep convolutional neural networks (DCNN) require large number of training data to avoid overfitting, which makes it unsuitable for processing small-scale image datasets. The transfer learning using DCNN (TCNN) reuses pre-trained layers to generate a mid-level image representation so that the optimization of more than millions CNN parameters can be avoided. By this way, overfitting problem in small-scale data can be alleviated. However, although now many public DCNNs have been trained and can be reused, the existing TCNNs are formed by only a single pre-trained DCNN structure and cannot make full use of multiple structures of pre-trained DCNNs. At the same time, the existing ensemble CNNs have not enough good representation ability. To address this problem, we combine the conventional ideas of ensemble CNNs and propose three ensemble TCNNs (TECNN). They are the voting method based on the combination of all TCNNs, the PickOver method by finding the optimal combination, and weighted method by finding weighted combination. Different from the existing ensemble CNNs, the proposed methods do not need to retrain the component CNNs and generate ensemble transferring representations by transferring the pre-trained mid-level parameters. The mathematical models of those three methods are also provided. Their versions of using fine-tuning are also compared in the experiments. In addition, we replace the Softmax classifier with ensemble linear classifiers in the full-connection layer. They outperform the current state of the art algorithms on Caltech ImageNet and some internet image data. All this research has released as an open source library called Transferring Image Ensemble Representations using Deep Convolutional Neural Networks (TECNN). The source codes and relevant datasets in different versions are available from: http://www.cquptshuyinxia.com/TECNN.html.},
  date         = {2019},
  doi          = {10.1109/ACCESS.2019.2912908},
  file         = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8779790:PDF},
  journaltitle = {IEEE Access},
  keywords     = {Task analysis, Training, Convolutional neural networks, Visualization, Image classification, Image representation, deep CNN, transferring CNN, transferring Learning},
  publisher    = {IEEE},
}

@Comment{jabref-meta: databaseType:bibtex;}
